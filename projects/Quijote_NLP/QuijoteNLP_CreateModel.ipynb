{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto NLP Quijote\n",
    "\n",
    "**Objetivo**\n",
    "Creación de un modelo de Deep Learning entrenado con los primeros **50 capitulos del Quijote**, para crear una contextualización artificial del contenido del libro y de esta manera poder predecir un nuevo texto en función a unas palabras dadas.\n",
    "\n",
    "**Requisitos**\n",
    "* Python 3.8\n",
    "* Tensorflow 2.x\n",
    "\n",
    "**Pasos de creación**\n",
    "* Adquirir el libro del Quijote en formato digital. https://www.gutenberg.org/ebooks/search/?query=quijote&submit_search=Go%21\n",
    "* Tratamiento de los datos\n",
    "* Creación del modelo usando redes LSTM (Large Short Term Memory)\n",
    "* Entrenamiento\n",
    "* Resultados y validación\n",
    "* Prediccón\n",
    "* Salvar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TzBKcqmSO-bq"
   },
   "outputs": [],
   "source": [
    "#Cargamos las librerias correspondientes\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from codecarbon import EmissionsTracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer\n",
    "Como la palabra sugiere tokenizar significa dividir la oración en una serie de tokens o en palabras simples, podemos decir que cada vez que hay un espacio en una oración agregamos una coma entre ellos para que nuestra oración se divida en tokens y cada palabra tenga un valor único de un número entero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "PLkTiMhlPWfq",
    "outputId": "af0789ef-4dec-4e02-e71c-f350f9cdc96a"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "data = open('Dataset/quijote_Lite.txt', encoding=\"utf8\").read()\n",
    "#data = open('/content/drive/My Drive/Colab Notebooks/Datasets/Vuelta_al_mundo.txt').read()\n",
    "\n",
    "#Limpiar de simbolos \n",
    "data = re.sub('[^a-zA-Z0-9á-ú\\¿\\?\\n\\.]', ' ', data)\n",
    "corpus = data.lower().split(\"\\n\")\n",
    "\n",
    "#Mostramos el cuerpo del texto ya limpio\n",
    "#print(corpus)\n",
    "corpus = sorted(list(set(corpus)))\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultado despues de realizar los **tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "colab_type": "code",
    "id": "0ZGKiyUcRbs6",
    "outputId": "8b64452d-fadb-4204-b846-6e015ff19c60"
   },
   "outputs": [],
   "source": [
    "#print(tokenizer.word_index)\n",
    "#print(total_words)\n",
    "#print(corpus)\n",
    "#print(len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparación de los datos\n",
    "Para mejorar el entrenamiento del modelo y poder tener más datos a partir de los obtenidos, se realiza una tecnica llamda **secuencia**. Que consiste en dividir cada oración en una más pequeña en forma de escalera, de esta forma se hará una predicción de entrenamiento por cada subdivisión de esa oración.\n",
    "\n",
    "<img src=\"images/secuencias.png\">\n",
    "\n",
    "Posteriormente se realiza un **Padding**. Es un método para convertir la matriz de enteros de longitud variable en una longitud fija, ya sea truncando (si la longitud es mayor que la longitud_máxima definida que trunca la matriz) o rellenando (si la longitud es más corta que la longitud_máxima, rellene la matriz con 0).\n",
    "\n",
    "<img src=\"images/Padding.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MhEV05uxPXrI"
   },
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "#Marcamos los tokens por cada frase\n",
    "for line in corpus:\n",
    "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
    "\t#Creamos frases más pequeñas en función a al original\n",
    "\t#for i in range(1, len(token_list)):\n",
    "\tfor i in range(1, len(token_list)): #usamos cada frase para aumentar el train en modo de escalera\n",
    "\t\tn_gram_sequence = token_list[:i+1]\n",
    "\t\tinput_sequences.append(n_gram_sequence)\n",
    "\n",
    "# pad sequences \n",
    "#Buscamos la frase más larga y las igualamos todas con ceros en la parte de adelante\n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# create predictors and label\n",
    "#Cogemos el ultimo valor como etiqueta (y) y el resto como (x)\n",
    "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "\n",
    "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mostramos algunos ejemplos del proceso**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "bGqeJ-NXPeGA",
    "outputId": "2a7a8d1f-298f-48de-a9fb-bd8043eb8d3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0  119 1725\n",
      "    1 4532    5   25]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(153835, 13850)\n",
      "(153835, 18)\n"
     ]
    }
   ],
   "source": [
    "print(xs[5])\n",
    "print(ys[5])\n",
    "print(ys.shape)\n",
    "print(xs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación del modelo\n",
    "\n",
    "* La primera capa incluye el número de palabras a entrenar y la salida de predicción que queremos mostrar, en este caso se hará una predicción de 50 palabras en función a la dada.\n",
    "\n",
    "* Usamos como optimizador Adam, aunque tambien se optienen buenos resultados con RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "colab_type": "code",
    "id": "zxvxkZIEPgz3",
    "outputId": "bae380ea-7c2d-41a8-f06b-d2d1f830a4a6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 21:45:37.468869: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-15 21:45:37.470901: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-15 21:45:37.472077: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-15 21:45:37.639127: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-15 21:45:37.640197: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-15 21:45:37.641173: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 18, 50)            692500    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 18, 100)           60400     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 100)               80400     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 13850)             1398850   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,242,250\n",
      "Trainable params: 2,242,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 50, input_length=max_sequence_len-1))\n",
    "#model.add(Bidirectional(LSTM(128)))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "adam = Adam(lr=0.001)\n",
    "rms=RMSprop(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "#earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
    "#filepath=\"/content/drive/My Drive/Colab Notebooks/Projects/QuijoteNLP/model/weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "filepath=\"model/weights-QuijoteNLP.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "lmh_OntsR9uh",
    "outputId": "c905c06b-4e6f-4626-829c-9706aabc3fc7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:45:47] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 21:45:47] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 21:45:47] No GPU found.\n",
      "[codecarbon INFO @ 21:45:47] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 21:45:47] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon INFO @ 21:45:48] CPU Model on constant consumption mode: Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz\n",
      "[codecarbon INFO @ 21:45:48] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 21:45:48]   Platform system: Linux-6.5.0-14-generic-x86_64-with-glibc2.35\n",
      "[codecarbon INFO @ 21:45:48]   Python version: 3.10.9\n",
      "[codecarbon INFO @ 21:45:48]   CodeCarbon version: 2.3.2\n",
      "[codecarbon INFO @ 21:45:48]   Available RAM : 15.458 GB\n",
      "[codecarbon INFO @ 21:45:48]   CPU count: 8\n",
      "[codecarbon INFO @ 21:45:48]   CPU model: Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz\n",
      "[codecarbon INFO @ 21:45:48]   GPU count: None\n",
      "[codecarbon INFO @ 21:45:48]   GPU model: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 21:45:51.896197: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 8522459000 exceeds 10% of free system memory.\n",
      "2024-01-15 21:45:58.930291: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-15 21:45:58.932211: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-15 21:45:58.933611: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-15 21:45:59.094712: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-15 21:45:59.095870: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-15 21:45:59.096907: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-15 21:45:59.907931: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-15 21:45:59.909391: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-15 21:45:59.910475: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-01-15 21:46:00.072021: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-01-15 21:46:00.073141: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-01-15 21:46:00.074188: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  76/1202 [>.............................] - ETA: 1:18 - loss: 7.5570 - accuracy: 0.0591"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:46:06] Energy consumed for RAM : 0.000024 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:46:06] Energy consumed for all CPUs : 0.000031 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:46:06] 0.000055 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 291/1202 [======>.......................] - ETA: 1:03 - loss: 6.9331 - accuracy: 0.0580"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:46:21] Energy consumed for RAM : 0.000048 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:46:21] Energy consumed for all CPUs : 0.000063 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:46:21] 0.000111 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 499/1202 [===========>..................] - ETA: 49s - loss: 6.7805 - accuracy: 0.0593"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:46:36] Energy consumed for RAM : 0.000072 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:46:36] Energy consumed for all CPUs : 0.000094 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:46:36] 0.000166 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 716/1202 [================>.............] - ETA: 34s - loss: 6.6777 - accuracy: 0.0587"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:46:51] Energy consumed for RAM : 0.000097 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:46:51] Energy consumed for all CPUs : 0.000125 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:46:51] 0.000222 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 916/1202 [=====================>........] - ETA: 20s - loss: 6.6228 - accuracy: 0.0598"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:47:06] Energy consumed for RAM : 0.000121 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:47:06] Energy consumed for all CPUs : 0.000156 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:47:06] 0.000277 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1132/1202 [===========================>..] - ETA: 4s - loss: 6.5760 - accuracy: 0.0607"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:47:21] Energy consumed for RAM : 0.000145 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:47:21] Energy consumed for all CPUs : 0.000187 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:47:21] 0.000332 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1202/1202 [==============================] - ETA: 0s - loss: 6.5607 - accuracy: 0.0611\n",
      "Epoch 1: accuracy improved from -inf to 0.06107, saving model to model/weights-QuijoteNLP.hdf5\n",
      "1202/1202 [==============================] - 88s 71ms/step - loss: 6.5607 - accuracy: 0.0611\n",
      "Epoch 2/10\n",
      " 123/1202 [==>...........................] - ETA: 1:26 - loss: 6.1891 - accuracy: 0.0681"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:47:36] Energy consumed for RAM : 0.000169 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:47:36] Energy consumed for all CPUs : 0.000219 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:47:36] 0.000388 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 340/1202 [=======>......................] - ETA: 1:03 - loss: 6.1636 - accuracy: 0.0698"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:47:51] Energy consumed for RAM : 0.000193 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:47:51] Energy consumed for all CPUs : 0.000250 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:47:51] 0.000443 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 549/1202 [============>.................] - ETA: 47s - loss: 6.1480 - accuracy: 0.0699"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:48:06] Energy consumed for RAM : 0.000217 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:48:06] Energy consumed for all CPUs : 0.000281 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:48:06] 0.000499 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 762/1202 [==================>...........] - ETA: 31s - loss: 6.1310 - accuracy: 0.0705"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:48:21] Energy consumed for RAM : 0.000241 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:48:21] Energy consumed for all CPUs : 0.000312 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:48:21] 0.000554 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 976/1202 [=======================>......] - ETA: 16s - loss: 6.1165 - accuracy: 0.0715"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:48:36] Energy consumed for RAM : 0.000266 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:48:36] Energy consumed for all CPUs : 0.000344 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:48:36] 0.000609 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1189/1202 [============================>.] - ETA: 0s - loss: 6.1006 - accuracy: 0.0738"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:48:51] Energy consumed for RAM : 0.000290 kWh. RAM Power : 5.7967658042907715 W\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190/1202 [============================>.] - ETA: 0s - loss: 6.1009 - accuracy: 0.0738"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:48:51] Energy consumed for all CPUs : 0.000375 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:48:51] 0.000665 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1202/1202 [==============================] - ETA: 0s - loss: 6.0992 - accuracy: 0.0740\n",
      "Epoch 2: accuracy improved from 0.06107 to 0.07401, saving model to model/weights-QuijoteNLP.hdf5\n",
      "1202/1202 [==============================] - 86s 72ms/step - loss: 6.0992 - accuracy: 0.0740\n",
      "Epoch 3/10\n",
      " 199/1202 [===>..........................] - ETA: 1:10 - loss: 5.8607 - accuracy: 0.0921"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:49:06] Energy consumed for RAM : 0.000314 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:49:06] Energy consumed for all CPUs : 0.000406 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:49:06] 0.000720 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 391/1202 [========>.....................] - ETA: 1:00 - loss: 5.8623 - accuracy: 0.0913"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:49:21] Energy consumed for RAM : 0.000338 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:49:21] Energy consumed for all CPUs : 0.000437 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:49:21] 0.000775 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 609/1202 [==============>...............] - ETA: 42s - loss: 5.8550 - accuracy: 0.0932"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:49:36] Energy consumed for RAM : 0.000362 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:49:36] Energy consumed for all CPUs : 0.000469 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:49:36] 0.000831 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 820/1202 [===================>..........] - ETA: 27s - loss: 5.8461 - accuracy: 0.0939"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:49:51] Energy consumed for RAM : 0.000386 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:49:51] Energy consumed for all CPUs : 0.000500 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:49:51] 0.000886 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1032/1202 [========================>.....] - ETA: 12s - loss: 5.8431 - accuracy: 0.0949"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:50:06] Energy consumed for RAM : 0.000410 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:50:06] Energy consumed for all CPUs : 0.000531 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:50:06] 0.000942 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1202/1202 [==============================] - ETA: 0s - loss: 5.8434 - accuracy: 0.0950\n",
      "Epoch 3: accuracy improved from 0.07401 to 0.09495, saving model to model/weights-QuijoteNLP.hdf5\n",
      "1202/1202 [==============================] - 87s 73ms/step - loss: 5.8434 - accuracy: 0.0950\n",
      "Epoch 4/10\n",
      "  25/1202 [..............................] - ETA: 1:20 - loss: 5.6630 - accuracy: 0.1050"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:50:21] Energy consumed for RAM : 0.000435 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:50:21] Energy consumed for all CPUs : 0.000562 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:50:21] 0.000997 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 237/1202 [====>.........................] - ETA: 1:07 - loss: 5.6780 - accuracy: 0.1053"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:50:36] Energy consumed for RAM : 0.000459 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:50:36] Energy consumed for all CPUs : 0.000594 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:50:36] 0.001052 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 445/1202 [==========>...................] - ETA: 53s - loss: 5.6718 - accuracy: 0.1053"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:50:51] Energy consumed for RAM : 0.000483 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:50:51] Energy consumed for all CPUs : 0.000625 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:50:51] 0.001108 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 662/1202 [===============>..............] - ETA: 38s - loss: 5.6727 - accuracy: 0.1063"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:51:06] Energy consumed for RAM : 0.000507 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:51:06] Energy consumed for all CPUs : 0.000656 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:51:06] 0.001163 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 870/1202 [====================>.........] - ETA: 23s - loss: 5.6726 - accuracy: 0.1066"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:51:21] Energy consumed for RAM : 0.000531 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:51:21] Energy consumed for all CPUs : 0.000687 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:51:21] 0.001219 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1088/1202 [==========================>...] - ETA: 8s - loss: 5.6726 - accuracy: 0.1060"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:51:36] Energy consumed for RAM : 0.000555 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:51:36] Energy consumed for all CPUs : 0.000719 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:51:36] 0.001274 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1202/1202 [==============================] - ETA: 0s - loss: 5.6724 - accuracy: 0.1064\n",
      "Epoch 4: accuracy improved from 0.09495 to 0.10636, saving model to model/weights-QuijoteNLP.hdf5\n",
      "1202/1202 [==============================] - 84s 70ms/step - loss: 5.6724 - accuracy: 0.1064\n",
      "Epoch 5/10\n",
      "  99/1202 [=>............................] - ETA: 1:21 - loss: 5.5624 - accuracy: 0.1160"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:51:51] Energy consumed for RAM : 0.000579 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:51:51] Energy consumed for all CPUs : 0.000750 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:51:51] 0.001329 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 324/1202 [=======>......................] - ETA: 1:00 - loss: 5.5377 - accuracy: 0.1171"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:52:06] Energy consumed for RAM : 0.000604 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:52:06] Energy consumed for all CPUs : 0.000781 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:52:06] 0.001385 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 536/1202 [============>.................] - ETA: 46s - loss: 5.5371 - accuracy: 0.1166"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:52:21] Energy consumed for RAM : 0.000628 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:52:21] Energy consumed for all CPUs : 0.000812 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:52:21] 0.001440 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 753/1202 [=================>............] - ETA: 31s - loss: 5.5336 - accuracy: 0.1171"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:52:36] Energy consumed for RAM : 0.000652 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:52:36] Energy consumed for all CPUs : 0.000844 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:52:36] 0.001496 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 976/1202 [=======================>......] - ETA: 15s - loss: 5.5390 - accuracy: 0.1170"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:52:51] Energy consumed for RAM : 0.000676 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:52:51] Energy consumed for all CPUs : 0.000875 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:52:51] 0.001551 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1192/1202 [============================>.] - ETA: 0s - loss: 5.5397 - accuracy: 0.1175"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:53:06] Energy consumed for RAM : 0.000700 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:53:06] Energy consumed for all CPUs : 0.000906 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:53:06] 0.001606 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1202/1202 [==============================] - ETA: 0s - loss: 5.5387 - accuracy: 0.1176\n",
      "Epoch 5: accuracy improved from 0.10636 to 0.11760, saving model to model/weights-QuijoteNLP.hdf5\n",
      "1202/1202 [==============================] - 83s 69ms/step - loss: 5.5387 - accuracy: 0.1176\n",
      "Epoch 6/10\n",
      " 209/1202 [====>.........................] - ETA: 1:07 - loss: 5.3701 - accuracy: 0.1278"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:53:21] Energy consumed for RAM : 0.000724 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:53:21] Energy consumed for all CPUs : 0.000937 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:53:21] 0.001662 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 427/1202 [=========>....................] - ETA: 52s - loss: 5.3896 - accuracy: 0.1265"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:53:36] Energy consumed for RAM : 0.000748 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:53:36] Energy consumed for all CPUs : 0.000969 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:53:36] 0.001717 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 645/1202 [===============>..............] - ETA: 38s - loss: 5.3988 - accuracy: 0.1261"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:53:51] Energy consumed for RAM : 0.000773 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:53:51] Energy consumed for all CPUs : 0.001000 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:53:51] 0.001772 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 862/1202 [====================>.........] - ETA: 23s - loss: 5.4036 - accuracy: 0.1260"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:54:06] Energy consumed for RAM : 0.000797 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:54:06] Energy consumed for all CPUs : 0.001031 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:54:06] 0.001828 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1079/1202 [=========================>....] - ETA: 8s - loss: 5.4067 - accuracy: 0.1259"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:54:21] Energy consumed for RAM : 0.000821 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:54:21] Energy consumed for all CPUs : 0.001062 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:54:21] 0.001883 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1202/1202 [==============================] - ETA: 0s - loss: 5.4116 - accuracy: 0.1260\n",
      "Epoch 6: accuracy improved from 0.11760 to 0.12596, saving model to model/weights-QuijoteNLP.hdf5\n",
      "1202/1202 [==============================] - 83s 69ms/step - loss: 5.4116 - accuracy: 0.1260\n",
      "Epoch 7/10\n",
      "  93/1202 [=>............................] - ETA: 1:15 - loss: 5.2543 - accuracy: 0.1365"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:54:36] Energy consumed for RAM : 0.000845 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:54:36] Energy consumed for all CPUs : 0.001094 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:54:36] 0.001939 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 309/1202 [======>.......................] - ETA: 1:01 - loss: 5.2837 - accuracy: 0.1350"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:54:51] Energy consumed for RAM : 0.000869 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:54:51] Energy consumed for all CPUs : 0.001125 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:54:51] 0.001994 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 525/1202 [============>.................] - ETA: 46s - loss: 5.2948 - accuracy: 0.1342"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:55:06] Energy consumed for RAM : 0.000893 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:55:06] Energy consumed for all CPUs : 0.001156 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:55:06] 0.002049 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 738/1202 [=================>............] - ETA: 32s - loss: 5.2959 - accuracy: 0.1334"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:55:21] Energy consumed for RAM : 0.000918 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:55:21] Energy consumed for all CPUs : 0.001187 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:55:21] 0.002105 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 953/1202 [======================>.......] - ETA: 17s - loss: 5.2953 - accuracy: 0.1330"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:55:36] Energy consumed for RAM : 0.000942 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:55:36] Energy consumed for all CPUs : 0.001219 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:55:36] 0.002160 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169/1202 [============================>.] - ETA: 2s - loss: 5.2938 - accuracy: 0.1330"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:55:51] Energy consumed for RAM : 0.000966 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:55:51] Energy consumed for all CPUs : 0.001250 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:55:51] 0.002216 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1202/1202 [==============================] - ETA: 0s - loss: 5.2948 - accuracy: 0.1327\n",
      "Epoch 7: accuracy improved from 0.12596 to 0.13271, saving model to model/weights-QuijoteNLP.hdf5\n",
      "1202/1202 [==============================] - 84s 70ms/step - loss: 5.2948 - accuracy: 0.1327\n",
      "Epoch 8/10\n",
      " 183/1202 [===>..........................] - ETA: 1:10 - loss: 5.1641 - accuracy: 0.1398"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:56:06] Energy consumed for RAM : 0.000990 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:56:06] Energy consumed for all CPUs : 0.001281 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:56:06] 0.002271 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 398/1202 [========>.....................] - ETA: 55s - loss: 5.1535 - accuracy: 0.1413"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:56:21] Energy consumed for RAM : 0.001014 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:56:21] Energy consumed for all CPUs : 0.001312 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:56:21] 0.002326 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 615/1202 [==============>...............] - ETA: 40s - loss: 5.1758 - accuracy: 0.1399"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:56:36] Energy consumed for RAM : 0.001038 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:56:36] Energy consumed for all CPUs : 0.001344 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:56:36] 0.002382 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 831/1202 [===================>..........] - ETA: 25s - loss: 5.1838 - accuracy: 0.1390"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:56:51] Energy consumed for RAM : 0.001062 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:56:51] Energy consumed for all CPUs : 0.001375 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:56:51] 0.002437 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1047/1202 [=========================>....] - ETA: 10s - loss: 5.1945 - accuracy: 0.1381"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:57:06] Energy consumed for RAM : 0.001087 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:57:06] Energy consumed for all CPUs : 0.001406 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:57:06] 0.002493 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1202/1202 [==============================] - ETA: 0s - loss: 5.1948 - accuracy: 0.1382\n",
      "Epoch 8: accuracy improved from 0.13271 to 0.13818, saving model to model/weights-QuijoteNLP.hdf5\n",
      "1202/1202 [==============================] - 84s 70ms/step - loss: 5.1948 - accuracy: 0.1382\n",
      "Epoch 9/10\n",
      "  59/1202 [>.............................] - ETA: 1:17 - loss: 5.0554 - accuracy: 0.1427"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:57:21] Energy consumed for RAM : 0.001111 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:57:21] Energy consumed for all CPUs : 0.001437 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:57:21] 0.002548 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 273/1202 [=====>........................] - ETA: 1:04 - loss: 5.0585 - accuracy: 0.1430"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:57:36] Energy consumed for RAM : 0.001135 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:57:36] Energy consumed for all CPUs : 0.001469 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:57:36] 0.002603 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 488/1202 [===========>..................] - ETA: 49s - loss: 5.0809 - accuracy: 0.1437"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:57:51] Energy consumed for RAM : 0.001159 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:57:51] Energy consumed for all CPUs : 0.001500 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:57:51] 0.002659 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 704/1202 [================>.............] - ETA: 34s - loss: 5.0829 - accuracy: 0.1445"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:58:06] Energy consumed for RAM : 0.001183 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:58:06] Energy consumed for all CPUs : 0.001531 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:58:06] 0.002714 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 918/1202 [=====================>........] - ETA: 19s - loss: 5.0918 - accuracy: 0.1434"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:58:21] Energy consumed for RAM : 0.001207 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:58:21] Energy consumed for all CPUs : 0.001562 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:58:21] 0.002770 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1133/1202 [===========================>..] - ETA: 4s - loss: 5.1036 - accuracy: 0.1420"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:58:36] Energy consumed for RAM : 0.001231 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:58:36] Energy consumed for all CPUs : 0.001594 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:58:36] 0.002825 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1202/1202 [==============================] - ETA: 0s - loss: 5.1061 - accuracy: 0.1422\n",
      "Epoch 9: accuracy improved from 0.13818 to 0.14218, saving model to model/weights-QuijoteNLP.hdf5\n",
      "1202/1202 [==============================] - 84s 70ms/step - loss: 5.1061 - accuracy: 0.1422\n",
      "Epoch 10/10\n",
      " 142/1202 [==>...........................] - ETA: 1:14 - loss: 4.9903 - accuracy: 0.1487"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:58:51] Energy consumed for RAM : 0.001256 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:58:51] Energy consumed for all CPUs : 0.001625 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:58:51] 0.002880 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 356/1202 [=======>......................] - ETA: 59s - loss: 5.0036 - accuracy: 0.1469"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:59:06] Energy consumed for RAM : 0.001280 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:59:06] Energy consumed for all CPUs : 0.001656 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:59:06] 0.002936 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 570/1202 [=============>................] - ETA: 44s - loss: 5.0018 - accuracy: 0.1487"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:59:21] Energy consumed for RAM : 0.001304 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:59:21] Energy consumed for all CPUs : 0.001687 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:59:21] 0.002991 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 788/1202 [==================>...........] - ETA: 28s - loss: 5.0088 - accuracy: 0.1476"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:59:36] Energy consumed for RAM : 0.001328 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:59:36] Energy consumed for all CPUs : 0.001718 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:59:36] 0.003046 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003/1202 [========================>.....] - ETA: 13s - loss: 5.0208 - accuracy: 0.1468"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 21:59:51] Energy consumed for RAM : 0.001352 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 21:59:51] Energy consumed for all CPUs : 0.001750 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 21:59:51] 0.003102 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1202/1202 [==============================] - ETA: 0s - loss: 5.0270 - accuracy: 0.1464\n",
      "Epoch 10: accuracy improved from 0.14218 to 0.14637, saving model to model/weights-QuijoteNLP.hdf5\n",
      "1202/1202 [==============================] - 84s 70ms/step - loss: 5.0270 - accuracy: 0.1464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 22:00:05] Energy consumed for RAM : 0.001375 kWh. RAM Power : 5.7967658042907715 W\n",
      "[codecarbon INFO @ 22:00:05] Energy consumed for all CPUs : 0.001779 kWh. Total CPU Power : 7.5 W\n",
      "[codecarbon INFO @ 22:00:05] 0.003153 kWh of electricity used since the beginning.\n"
     ]
    }
   ],
   "source": [
    "with EmissionsTracker() as tracker:\n",
    "    history = model.fit(xs, ys, epochs=10, batch_size=128, verbose=1,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:3333/\n",
      "\n",
      " * Serving Flask app 'codecarbon.viz.carbonboard'\n",
      " * Debug mode: off\n",
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:3333\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "127.0.0.1 - - [15/Jan/2024 22:01:54] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:01:55] \"GET /_dash-layout HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:01:55] \"GET /_dash-dependencies HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:01:55] \"GET /_favicon.ico?v=2.12.1 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:01:55] \"\u001b[36mGET /_dash-component-suites/dash/dcc/async-dropdown.js HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:01:55] \"\u001b[36mGET /_dash-component-suites/dash/dcc/async-graph.js HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:01:55] \"\u001b[36mGET /_dash-component-suites/dash/dcc/async-plotlyjs.js HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:01:55] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:01:55] \"\u001b[36mGET /_dash-component-suites/dash/dash_table/async-highlight.js HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:01:55] \"\u001b[36mGET /_dash-component-suites/dash/dash_table/async-table.js HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:01:55] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:01:55] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:01:55] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:01:55] \"\u001b[36mGET /assets/house_icon.png HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:01:55] \"\u001b[36mGET /assets/tv_icon.png HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:01:55] \"\u001b[36mGET /assets/car_icon.png HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:01:56] \"GET /_favicon.ico?v=2.12.1 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:01:57] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:01:57] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:01:57] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:01:57] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:01:57] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:03:59] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:04:00] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:04:00] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:04:00] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:04:00] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:04:00] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:04:00] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:04:00] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:04:00] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:04:16] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:04:16] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:04:16] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:04:16] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:04:16] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:04:16] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:04:17] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:04:17] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Jan/2024 22:04:17] \"POST /_dash-update-component HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "!carbonboard --filepath=\"emissions.csv\" --port=3333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9CvgUbHbPjww"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "XT4XmpYMPoH4",
    "outputId": "fde69c6d-91ff-4088-bfa6-2efd00d58bd2"
   },
   "outputs": [],
   "source": [
    "plot_graphs(history, 'accuracy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción de un texto nuevo\n",
    "* Le damos unas palabras para que pueda crear unas lineas contextualizadas en el Quijote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "OimcHXq0Po7Z",
    "outputId": "bf2e77b7-5838-4f77-fb0d-e3fb6353e089"
   },
   "outputs": [],
   "source": [
    "seed_text = \"leer libros de caballerías\"\n",
    "next_words = 50\n",
    "  \n",
    "for _ in range(next_words):\n",
    "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "\tpredicted = model.predict_classes(token_list, verbose=0)\n",
    "\toutput_word = \"\"\n",
    "\tfor word, index in tokenizer.word_index.items():\n",
    "\t\tif index == predicted:\n",
    "\t\t\toutput_word = word\n",
    "\t\t\tbreak\n",
    "\tseed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se guarda la predicción en un archivo de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "usm3bZLWMFrx"
   },
   "outputs": [],
   "source": [
    "file = open(\"prediction.txt\", \"w\") \n",
    "file.write(seed_text) \n",
    "file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YYtokmLIg2Zz",
    "outputId": "fbf47681-6607-4cfd-bde7-4d26bad2b5f5"
   },
   "outputs": [],
   "source": [
    "e = model.layers[0]\n",
    "weights = e.get_weights()[0]\n",
    "print(weights.shape) # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LtJwKrzrcq1Z",
    "outputId": "875cc1ab-58cf-43e5-fe21-8bd59266f13a"
   },
   "outputs": [],
   "source": [
    "#cantidad de palabras unicas\n",
    "len(tokenizer.word_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u0lRlhleT01L"
   },
   "outputs": [],
   "source": [
    "#Convertimos el diccionario en una lista, obteniendo solo las palabras\n",
    "words_list = [(k) for k in tokenizer.word_index.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "EBvA01deg5tJ",
    "outputId": "b96c99a0-9d3d-4881-842e-343f8955def7"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for num, word in enumerate(words_list):\n",
    "  vec = weights[num+1] # skip 0, it's padding.\n",
    "  out_m.write(word + \"\\n\")\n",
    "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()\n",
    "\n",
    "try:\n",
    "  from google.colab import files\n",
    "except ImportError:\n",
    "   pass\n",
    "else:\n",
    "  files.download('vecs.tsv')\n",
    "  files.download('meta.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rh3LrlRlcNV_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "QuijoteNLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
